{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mNQ-I1PUU-PH"
   },
   "source": [
    "# hw3 - ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ENj9WzCU-SK"
   },
   "source": [
    "## 1 Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import category_encoders as ec\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_MDgqWu9U-U-"
   },
   "source": [
    "Загрузите и предобработайте данные (по своему усмотрению) из hw1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "IbSGi7csVlYZ"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=[\"G3\"])\n",
    "y = data[\"G3\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Em0erMH6WyEV"
   },
   "source": [
    "## 2 Обоснуйте выбор слабых (базовых) алгоритмов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KqC_5cbgWyML"
   },
   "source": [
    "Выбрал слабые алгоритме основываясь на алгоритмах из первой домашке, которые хорошо себя в целом показали + решил добавить DecisionTreeClassifier, так как тоже себя хорошо показывает на этих данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R08QEdnPU-X5"
   },
   "source": [
    "## 3 Постройте решение на основе подхода Blending"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sF_TRbWxYQ8p"
   },
   "source": [
    "Правила:\n",
    "- Нужно использовать вероятности\n",
    "- Предложите что-то лучше, чем брать среднее от предсказаний моделей (оценивать уверенность алгоритмов, точности и т.д.)\n",
    "- Заставьте базовые алгоритмы быть некорелированными\n",
    "- Добавьте рандома (например, стройте ваши алгоритмы на разных выборках, по разному предобрабатывайте данные или применяйте для разных признаков соответствующие алгоритмы ... )\n",
    "- Проявите смекалку\n",
    "- Цель: метрика MSE на тесте меньше 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "I-Kw6bNqPUoj"
   },
   "outputs": [],
   "source": [
    "def classifier_models():\n",
    "    models = {\n",
    "        \"DecisionTreeClassifier\": DecisionTreeClassifier(),\n",
    "        \"knn\": KNeighborsClassifier(),\n",
    "        \"svm\": SVC(probability=True),\n",
    "        \"lr\" : LogisticRegression()\n",
    "    }\n",
    "    meta_model = SVC()\n",
    "    return models, meta_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_grids():\n",
    "    grid = {\n",
    "        \"DecisionTreeClassifier\": {\n",
    "            'max_depth': np.arange(1, 2), \n",
    "            \"splitter\": [\"best\", \"random\"],\n",
    "            \"criterion\": [\"gini\", \"entropy\", \"log_loss\"]\n",
    "        },\n",
    "        \"knn\": {\n",
    "            \"n_neighbors\": np.arange(10, 30),\n",
    "            'metric': ['euclidean', 'manhattan', 'minkowski']\n",
    "        },\n",
    "        \"svm\": {\n",
    "            \"class_weight\": [\"balanced\"],\n",
    "            \"kernel\": [\"linear\", \"poly\", \"rbf\"],\n",
    "            \"C\": np.linspace(0.001, 10, 20),\n",
    "            \"max_iter\": [50, 500, 1000, 10000]\n",
    "        },\n",
    "        \"lr\": {\n",
    "            \"solver\": ['saga', 'lgbfs'],\n",
    "            \"C\": [1, 2, 3],\n",
    "            \"penalty\": [\"l1\",\"l2\"],\n",
    "            \"max_iter\": [100, 200]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    meta_grid = {\n",
    "        \"class_weight\": [\"balanced\", \"uniform\"],\n",
    "        \"kernel\": [\"linear\", \"poly\", \"rbf\"],\n",
    "        \"C\": np.linspace(0.001, 10, 20)\n",
    "    }\n",
    "    return grid, meta_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regressor_models():\n",
    "    models = {\n",
    "        \"knn\": KNeighborsRegressor(),\n",
    "        \"svr\": SVR(),\n",
    "        \"lr\" : ElasticNet()\n",
    "    }\n",
    "\n",
    "    meta_model = SVR()\n",
    "    return models, meta_model\n",
    "\n",
    "def regressor_grids():\n",
    "    grid = {\n",
    "        \"knn\": {\n",
    "            \"n_neighbors\": np.arange(1, 60)\n",
    "        },\n",
    "        \"svr\": {\n",
    "            \"kernel\": [\"linear\", \"poly\", \"rbf\"],\n",
    "            \"C\": np.linspace(0.001, 10, 20)\n",
    "        },\n",
    "        \"lr\": {\n",
    "            \"fit_intercept\": [True]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    meta_grid = {\n",
    "        \"kernel\": [\"linear\", \"poly\", \"rbf\"],\n",
    "        \"C\": np.linspace(0.001, 10, 20)\n",
    "    }\n",
    "    return grid, meta_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_base_models(data, models, grid, verbose=False):\n",
    "    for model_name in tqdm(models.keys()):\n",
    "        if verbose:\n",
    "            print(f\"Model: {model_name}\")\n",
    "        models[model_name] = fit_predict_CV(data[\"X\"], data[\"y\"], models[model_name], grid[model_name], verbose=verbose)\n",
    "\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_predict_CV(X, y, model_type, params_grid, verbose=False):\n",
    "    model_cv = GridSearchCV(model_type, params_grid, cv=KFold(), refit=True)\n",
    "    model_cv.fit(X, y)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Best hyperparameters: \", model_cv.best_params_)\n",
    "        print(\"Best score: \", model_cv.best_score_)\n",
    "\n",
    "    return model_cv.best_estimator_\n",
    "\n",
    "def train_base_models(data, models, grid, verbose=False):\n",
    "    for model_name in tqdm(models.keys()):\n",
    "        if verbose:\n",
    "            print(\"Model:\",{model_name})\n",
    "        models[model_name] = fit_predict_CV(data[\"X\"], data[\"y\"], models[model_name], grid[model_name], verbose=verbose)\n",
    "\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_base_models(X, models, models_type=None):\n",
    "    if models_type is None:\n",
    "        raise ValueError(\"models_type must be non None\")\n",
    "    predictions = None\n",
    "    if models_type == \"cls\":\n",
    "        for model in models.values():\n",
    "            pred = model.predict_proba(X)\n",
    "            if predictions is None:\n",
    "                predictions = pred\n",
    "            else:\n",
    "                predictions = np.hstack([predictions, pred])\n",
    "    if models_type == \"reg\":\n",
    "         for model in models.values():\n",
    "            pred = model.predict(X)\n",
    "            if predictions is None:\n",
    "                predictions = pred[:, None]\n",
    "            else:\n",
    "                predictions = np.hstack([predictions, pred[:, None]])\n",
    "\n",
    "    return predictions\n",
    "\n",
    "def train_meta_model(data, models, meta_model, grid, models_type=None, verbose=False):\n",
    "    X_train_meta_model = predict_base_models(data[\"X\"], models, models_type)\n",
    "    return fit_predict_CV(X_train_meta_model, data[\"y\"], meta_model, grid, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_blending(data, models, meta_model, models_type=None):\n",
    "    models_preds = predict_base_models(data[\"X\"], models, models_type)\n",
    "    predictions = meta_model.predict(models_preds)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.2, shuffle=True, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "\n",
    "data_train = {\n",
    "    \"X\": scaler.transform(x_train),\n",
    "    \"y\": y_train\n",
    "}\n",
    "data_val = {\n",
    "    \"X\": scaler.transform(x_val),\n",
    "    \"y\": y_val\n",
    "}\n",
    "data_test = {\n",
    "    \"X\": scaler.transform(x_test),\n",
    "    \"y\": y_test\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "models, meta_model = classifier_models()\n",
    "grid, meta_model_grid = classifier_grids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed54c02e99ce46d48f04863407138eca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: {'DecisionTreeClassifier'}\n",
      "Best hyperparameters:  {'criterion': 'entropy', 'max_depth': 1, 'splitter': 'random'}\n",
      "Best score:  0.1896551724137931\n",
      "Model: {'knn'}\n",
      "Best hyperparameters:  {'metric': 'euclidean', 'n_neighbors': 22}\n",
      "Best score:  0.1724137931034483\n",
      "Model: {'svm'}\n",
      "Best hyperparameters:  {'C': 4.737368421052632, 'class_weight': 'balanced', 'kernel': 'rbf', 'max_iter': 50}\n",
      "Best score:  0.16551724137931037\n",
      "Model: {'lr'}\n",
      "Best hyperparameters:  {'C': 1, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga'}\n",
      "Best score:  0.13793103448275862\n"
     ]
    }
   ],
   "source": [
    "best_models = train_base_models(data_train, models, grid, verbose=True)\n",
    "trained_meta_model = train_meta_model(\n",
    "    data_val,\n",
    "    best_models,\n",
    "    meta_model,\n",
    "    meta_model_grid,\n",
    "    models_type=\"cls\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.106\n",
      "MSE:      8.937\n"
     ]
    }
   ],
   "source": [
    "predictions = np.round(predict_blending(data_test, best_models, trained_meta_model, models_type=\"cls\"))\n",
    "accuracy = accuracy_score(data_test[\"y\"], np.round(predictions))\n",
    "mse = mean_squared_error(data_test[\"y\"], np.round(predictions))\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.3}\")\n",
    "print(f\"MSE:      {mse:.5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iRmBr8VRWolP"
   },
   "source": [
    "## 4 Постройте решение на основе подхода Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5oYYsgNRasfs"
   },
   "source": [
    "Правила:\n",
    "- Реализуйте пайплайн обучения и предсказания (например, sklearn.pipeline или класс)\n",
    "- Проведите оптимизацию пайплайна\n",
    "- Оцените вклад каждого базового алгоритма в итоговое предсказание\n",
    "- Цель: метрика MSE на тесте меньше 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Bc74w6f_WotV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.198\n",
      "MSE:      8.6044\n"
     ]
    }
   ],
   "source": [
    "models = classifier_models()[0]\n",
    "estimators = []\n",
    "for model_name in models.keys():\n",
    "    model_pipeline = make_pipeline(\n",
    "        StandardScaler(),\n",
    "        models[model_name]\n",
    "    )\n",
    "    estimators += [(model_name, model_pipeline)]\n",
    "\n",
    "folds = StratifiedKFold(n_splits=3, shuffle=True)\n",
    "\n",
    "clf = StackingClassifier(\n",
    "    estimators=estimators,\n",
    "    final_estimator=LogisticRegression(),\n",
    "    cv=folds\n",
    ")\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=1)\n",
    "\n",
    "clf = clf.fit(x_train, y_train)\n",
    "predictions = clf.predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, np.round(predictions))\n",
    "mse = mean_squared_error(y_test, np.round(predictions))\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.3}\")\n",
    "print(f\"MSE:      {mse:.5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gOSFp3Y9cO4r"
   },
   "source": [
    "## * Доп задание (не обязательно, но решение будет поощряться)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "biFb-0hPcqk6"
   },
   "source": [
    "Правила:\n",
    "- Постройте несколько сильных алгоритмов разного класса (это может быть бустинг, нейросеть, ансамбль слабых алгоритмов, алгоритм на статистике, что придумаете)\n",
    "- Реализуйте \"управляющий\" алгоритм, который на основе входных данных будет выбирать, какой из  сильных алгоритмов запустить (не на основе их работы, а именно на основе данных)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yD-jrz7CcPAo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e_vb2_cxVyWP"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
